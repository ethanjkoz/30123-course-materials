{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanjkoz/30123-course-materials/blob/main/2M_CPU_Parallelism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU Parallelism: Vector Processing and Multithreading\n",
        "\n",
        "In this notebook, we'll explore how you can achieve parallel execution on CPUs by way of vector processing and multi-threading, using `numba`. Here, we'll focus on incorporating `numba` into a common analytical workflow -- that of applying some function to a column (or several columns) in your DataFrame and creating a new, derived column for further study.\n",
        "\n",
        "For this demonstration, we'll be working with a small sample of [AirBnB's listing data](http://insideairbnb.com/get-the-data.html), a large dataset that contains information on AirBnBs from around the world on a month-by-month basis."
      ],
      "metadata": {
        "id": "5a1uybrnHlFf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P6m9tPaaGqIG",
        "outputId": "a6f95abb-5b6c-42d7-8a76-e93d656049ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-6aa2216b22a2>:1: NumbaPendingDeprecationWarning: The 'pycc' module is pending deprecation. Replacement technology is being developed.\n",
            "\n",
            "Pending Deprecation in Numba 0.57.0. For more information please see: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-the-numba-pycc-module\n",
            "  from numba.pycc import CC\n"
          ]
        }
      ],
      "source": [
        "from numba.pycc import CC\n",
        "from numba import vectorize, jit, prange\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we can load in our AirBnB data (included in this directory) and see what it looks like (note that this data is from the city of Chicago, compiled by AirBnB in April 2021):\n"
      ],
      "metadata": {
        "id": "Sz2ibxYyIZf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('listings_chi.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "JLyeBJS0G84E",
        "outputId": "cb0ddb9f-2dcb-44ad-d499-b1c7b7a24eed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'listings_chi.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-903a0ad2d873>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'listings_chi.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'listings_chi.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qvmzcvRfmWEH",
        "outputId": "cec4c34d-4939-42a3-cf3d-d825717b930c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll notice that two of the columns in the DataFrame are \"latitude\" and \"longitude\" -- spatial coordinates corresponding to AirBnB locations. Let's say that we're interested in creating a derived column from these coordinates, measuring how far each AirBnB is from the MACSS building at the University of Chicago (so that we can compute some further summary statistics about this column). The longitude and latitude of the 1155 E. 60th Street building is as follows:"
      ],
      "metadata": {
        "id": "TWtWQnK2XDgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "macss = {'longitude': -87.5970978, 'latitude': 41.7856443}"
      ],
      "metadata": {
        "id": "sYUVOKP2jJY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To measure distance between coordinates, we can write a Python function to calculate the distance between two sets of (longitude, latitude) coordinates using [great-circle distance](https://en.wikipedia.org/wiki/Great-circle_distance). We'll write another version of this function that uses `numba` to compile this function ahead of time in two ways: one that performs the calcuation on individual scalar values and another that does so via vector processing."
      ],
      "metadata": {
        "id": "rzhZBNt9IkaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(lon1, lat1, lon2, lat2):\n",
        "    '''\n",
        "    Calculate the circle distance between two points\n",
        "    on the earth (specified in decimal degrees)\n",
        "    '''\n",
        "    # convert decimal degrees to radians\n",
        "    lon1, lat1 = map(np.radians, [lon1, lat1])\n",
        "    lon2, lat2 = map(np.radians, [lon2, lat2])\n",
        "\n",
        "    # haversine formula\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "    # 6367 km is the radius of the Earth\n",
        "    km = 6367 * c\n",
        "    m = km * 1000\n",
        "    return m\n",
        "\n",
        "# Use Numba to compile this same function in a module named `aot`\n",
        "# in both a vectorized and non-vectorized form\n",
        "cc = CC('aot')\n",
        "\n",
        "@cc.export('distance', 'f8(f8,f8,f8,f8)')\n",
        "@cc.export('distance_v', 'f8[:](f8[:],f8[:],f8,f8)')\n",
        "def distance_numba(lon1, lat1, lon2, lat2):\n",
        "    '''\n",
        "    Calculate the circle distance between two points\n",
        "    on the earth (specified in decimal degrees)\n",
        "\n",
        "    (distance: Numba-accelerated; distance_v: Numba-accelerated + vectorized)\n",
        "    '''\n",
        "    # convert decimal degrees to radians\n",
        "    lon1, lat1 = map(np.radians, [lon1, lat1])\n",
        "    lon2, lat2 = map(np.radians, [lon2, lat2])\n",
        "\n",
        "    # haversine formula\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "    # 6367 km is the radius of the Earth\n",
        "    km = 6367 * c\n",
        "    m = km * 1000\n",
        "    return m\n",
        "cc.compile()\n",
        "\n",
        "import aot # import in module we just compiled"
      ],
      "metadata": {
        "id": "-yg1QLxoHeeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we could use the common dataframe method `apply` to apply our function to each row in our dataframe. Note, though, that this is really slow and is effectively equivalent to looping over each row in the dataframe using our pre-compiled distance function."
      ],
      "metadata": {
        "id": "lwXsn1yJXdrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df.loc[:,'distance_from_macss'] = df[['longitude', 'latitude']] \\\n",
        "                                    .apply(lambda x: distance(x.longitude,\n",
        "                                                              x.latitude,\n",
        "                                                              macss['longitude'],\n",
        "                                                              macss['latitude']),\n",
        "                                           axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdBWEhTvI49h",
        "outputId": "4c9d2c07-db69-4dd9-a054-c2ddadc26236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191 ms ± 4.12 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df.loc[:,'distance_from_macss'] = df[['longitude', 'latitude']] \\\n",
        "                                    .apply(lambda x: aot.distance(\n",
        "                                        x.longitude,\n",
        "                                        x.latitude,\n",
        "                                        macss['longitude'],\n",
        "                                        macss['latitude']),\n",
        "                                      axis=1)\n",
        "# faster looping, but still looping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzZl123NOine",
        "outputId": "7998b91b-7c57-4684-af88-ed8366e50b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103 ms ± 669 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "distance_lst = []\n",
        "for lon, lat in df[['longitude', 'latitude']].values:\n",
        "  dist = distance(lon,\n",
        "                  lat,\n",
        "                  macss['longitude'],\n",
        "                  macss['latitude'])\n",
        "  distance_lst.append(dist)\n",
        "df.loc[:,'distance_from_macss'] = distance_lst\n",
        "# see that this solution is essentially the same!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahUoKAZaJRRo",
        "outputId": "e7e2a1e5-0660-425a-ad95-2a4f7393be0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106 ms ± 25.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you're working with `numpy` or `pandas` arrays it's generally better to to take advantage of their capacity for parallel vector processing (up to the capabilities of your CPU). The built-in `numpy` functions in our distance function, for instance, will all take both scalars and vectors as input and be able to perform vectorized operations on multiple elements of our arrays in parallel. For instance, even without compiling our code with `numba`, we see ~50x speedup simply by using existing `numpy` functionality:"
      ],
      "metadata": {
        "id": "JB3phciKYY5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df.loc[:,'distance_from_macss'] = distance(df.longitude,\n",
        "                                           df.latitude,\n",
        "                                           macss['longitude'],\n",
        "                                           macss['latitude'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aM6TxmANdfL",
        "outputId": "57a8a821-ead4-4c6a-f3e2-cf91a0388956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.38 ms ± 107 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our `numba` pre-compiled solution is even faster, for the reasons discussed last week:"
      ],
      "metadata": {
        "id": "4rbq0YE5Zl1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "# note `.values`! Numba doesn't accept Pandas objects (but NumPy is OK)\n",
        "df.loc[:,'distance_from_macss'] = aot.distance_v(df.longitude.values,\n",
        "                                                 df.latitude.values,\n",
        "                                                 macss['longitude'],\n",
        "                                                 macss['latitude'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaP8wkbyO8cG",
        "outputId": "2a026cab-0f63-44b3-e343-853e5f0757cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "588 µs ± 8.44 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned above, the main reason for our vector processing speedup is that our computation involved a lot of predefined NumPy functions that are already compiled for us to perform these operations via vector processing.\n",
        "\n",
        "Note, for instance that `np.sin` (one of the functions we used) is a \"Universal Function\" (`ufunc`):"
      ],
      "metadata": {
        "id": "YJXG85NLouXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(np.sin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eo82EuuwfNV",
        "outputId": "28948742-7cba-4e31-c12f-1dc2077acfc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ufunc"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to compile our own `ufunc`s to perform vectorized operations on NumPy arrays, `numba` includes a `@vectorize` decorator as well that will compile a `ufunc` for us. This can be useful if our particular application is not supported by the existing set of `numpy` universal function.\n",
        "\n",
        "Let's write a `ufunc`, for instance, that checks a variety of conditions in our dataset and assigns categorical labels to postings based on whether they match the expected conditions or not:"
      ],
      "metadata": {
        "id": "TaJLHtYu4tmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@vectorize(['i8(i8,i8)'])\n",
        "def check_conditions_v(id, number_of_reviews):\n",
        "    check_lst = set([i for i in range(5700, 5800)])\n",
        "    if (id in check_lst) and (number_of_reviews > 50):\n",
        "      return 0\n",
        "    elif (number_of_reviews > 50):\n",
        "      return 1\n",
        "    return 2\n",
        "\n",
        "df.loc[:, 'condition'] = check_conditions_v(df.host_id, df.number_of_reviews)\n",
        "df.loc[:5, ['host_id', 'number_of_reviews', 'condition']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "9kV_c86sdyDS",
        "outputId": "a1e4ee10-e8c0-4eaf-cfd9-03d3749e4a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   host_id  number_of_reviews  condition\n",
              "0     2613                182          1\n",
              "1     5775                395          0\n",
              "2    17928                394          1\n",
              "3    33004                 54          1\n",
              "4    33004                 22          2\n",
              "5    40731                  9          2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbf5ab30-e1ce-47e2-b8be-e7361b6029b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>host_id</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2613</td>\n",
              "      <td>182</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5775</td>\n",
              "      <td>395</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17928</td>\n",
              "      <td>394</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33004</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33004</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>40731</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbf5ab30-e1ce-47e2-b8be-e7361b6029b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbf5ab30-e1ce-47e2-b8be-e7361b6029b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbf5ab30-e1ce-47e2-b8be-e7361b6029b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f9bc8e6-1b50-4205-8541-355db44f2fe5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f9bc8e6-1b50-4205-8541-355db44f2fe5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f9bc8e6-1b50-4205-8541-355db44f2fe5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"host_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15802,\n        \"min\": 2613,\n        \"max\": 40731,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5775,\n          40731,\n          17928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_of_reviews\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 180,\n        \"min\": 9,\n        \"max\": 395,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          182,\n          395,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"condition\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Multithreading\" in `numba`\n",
        "\n",
        "`numba` allows us to achieve additional parallelism via optional multithreading capabilities. In Colab, we can check and see that we do have access to a minimal amount of parallelism via multithreading (two threads!) to demonstrate:"
      ],
      "metadata": {
        "id": "2zN--AXfIwfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import get_num_threads\n",
        "get_num_threads()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeqzClAJ4n4P",
        "outputId": "178bb091-9eaa-4550-e0a3-74e58d2da190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of vector processing, we can split up our input array into smaller arrays which are assigned to different threads to execute in parallel. This can be achieved simply by setting our compilation target to 'parallel' in the `vectorize` decorator:"
      ],
      "metadata": {
        "id": "CvpCf15bQNWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@vectorize(['i8(i8,i8)'], target='parallel')\n",
        "def check_conditions_v_mt(id, number_of_reviews):\n",
        "    check_lst = set([i for i in range(5700, 5800)])\n",
        "    if (id in check_lst) and (number_of_reviews > 50):\n",
        "      return 0\n",
        "    elif (number_of_reviews > 50):\n",
        "      return 1\n",
        "    return 2"
      ],
      "metadata": {
        "id": "Xy7MLsTLO_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test to see how our vectorized version of the function compares to our vectorized + multithreaded version (increasing data size so that the difference is more distinguishable):"
      ],
      "metadata": {
        "id": "R9kcoCvIQkIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# increase data size\n",
        "host_ids = np.tile(df.host_id.values, 200)\n",
        "num_reviews = np.tile(df.number_of_reviews.values, 200)\n",
        "\n",
        "# compare original runtime\n",
        "%timeit check_conditions_v(host_ids, num_reviews)\n",
        "# to multi-threading version\n",
        "%timeit check_conditions_v_mt(host_ids, num_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efhi7yiCH8wa",
        "outputId": "bfb1f970-875c-4549-9ad3-c64583fa1dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.28 s ± 370 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "1.99 s ± 415 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We see a slight speedup even here in Colab, but we are working on limited resources, so it is not too dramatic. However, working on 8 threads (2 threads per physical CPU core) on my local machine, you can see a significant performance boost via multithreading:\n",
        "\n",
        "```ipython\n",
        "In [38]: # compare original runtime\n",
        "    ...: %timeit check_conditions_v(host_ids, num_reviews)\n",
        "    ...: # to multi-threading version\n",
        "    ...: %timeit check_conditions_v_mt(host_ids, num_reviews)\n",
        "1.27 s ± 103 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
        "566 ms ± 5.04 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
        "```\n",
        "\n",
        "Note that we can also use `numba` to automatically parallelize loops for us via multithreading. Let's assume, for instance, that we are working on a dataset with over 60m records (increasing the size of our dataset again to more easily distinguish performance differences across versions of our functions) and we want to (log) transform all of the distances we've computed and then compute the average distance of all postings from the MACSS building.\n",
        "\n",
        "In `numpy`, we could compute this statistic like so:"
      ],
      "metadata": {
        "id": "oCFGSCMfRf_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances = np.tile(df.distance_from_macss.values, 10000)\n",
        "len(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKl9U4qWy1qm",
        "outputId": "e9828970-d567-4777-a5f1-a944f8ad80e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63860000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit np.log(distances).sum() / len(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZS7F8JD2yov",
        "outputId": "f5d95c7f-5d89-46a0-efb4-a94e1236a823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "793 ms ± 193 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The time it takes to run this code is similar to compiling a function to do the same in `nopython` mode in `numba` (utilizing vector processing on one thread):"
      ],
      "metadata": {
        "id": "GzOoBZlLTapf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True)\n",
        "def average_log_distance_from_macss(distance_from_macss):\n",
        "  size = len(distance_from_macss)\n",
        "  transformed_dist = np.log(distance_from_macss)\n",
        "  sum_d = 0\n",
        "\n",
        "  for i in range(size):\n",
        "    sum_d += transformed_dist[i]\n",
        "\n",
        "  avg = sum_d / size\n",
        "  return avg\n",
        "\n",
        "%timeit average_log_distance_from_macss(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2N88m8c4Q-i",
        "outputId": "4f24b177-213c-4d0d-d551-9f99a70bee41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "922 ms ± 6.89 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`numba` can parallelize such functions for us by setting `parallel=True` and replacing `range` in our loop definition with `prange` to explicitly parallelize our loop iterations across available threads:"
      ],
      "metadata": {
        "id": "W1ebwzeRUPcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True, parallel=True)\n",
        "def average_log_distance_from_macss_mt(distance_from_macss):\n",
        "  size = len(distance_from_macss)\n",
        "  transformed_dist = np.log(distance_from_macss)\n",
        "  sum_d = 0\n",
        "\n",
        "  # note the use `prange` instead of `range` to explicitly parallelize loop\n",
        "  # across threads\n",
        "  for i in prange(size):\n",
        "    sum_d += transformed_dist[i]\n",
        "\n",
        "  avg = sum_d / size\n",
        "  return avg\n",
        "\n",
        "%timeit average_log_distance_from_macss_mt(distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIfXarefkGAK",
        "outputId": "087231f4-e833-44a3-f25d-a60d10550691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "511 ms ± 3.78 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...resulting in a speedup even over the original `numpy` solution. If we use the built-in parallel diagnostics method for our function, we can see that `numba` achieves this speedup by inferring which steps in our code can be performed together and \"fusing\" the parallel code together for execution:"
      ],
      "metadata": {
        "id": "jkPl9_37Uu7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_log_distance_from_macss_mt.parallel_diagnostics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7hIvrR3Qguu",
        "outputId": "082909ef-2de9-43cc-cb13-43d4c51c116a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "================================================================================\n",
            " Parallel Accelerator Optimizing:  Function average_log_distance_from_macss_mt, \n",
            "<ipython-input-18-2d539ca9ec92> (1)  \n",
            "================================================================================\n",
            "\n",
            "\n",
            "Parallel loop listing for  Function average_log_distance_from_macss_mt, <ipython-input-18-2d539ca9ec92> (1) \n",
            "-------------------------------------------------------------------------------|loop #ID\n",
            "@jit(nopython=True, parallel=True)                                             | \n",
            "def average_log_distance_from_macss_mt(distance_from_macss):                   | \n",
            "  size = len(distance_from_macss)                                              | \n",
            "  transformed_dist = np.log(distance_from_macss)-------------------------------| #0\n",
            "  sum_d = 0                                                                    | \n",
            "                                                                               | \n",
            "  # note the use `prange` instead of `range` to explicitly parallelize loop    | \n",
            "  # across threads                                                             | \n",
            "  for i in prange(size):-------------------------------------------------------| #1\n",
            "    sum_d += transformed_dist[i]                                               | \n",
            "                                                                               | \n",
            "  avg = sum_d / size                                                           | \n",
            "  return avg                                                                   | \n",
            "------------------------------ After Optimisation ------------------------------\n",
            "Parallel region 0:\n",
            "+--0 (parallel, fused with loop(s): 1)\n",
            "\n",
            "\n",
            " \n",
            "Parallel region 0 (loop #0) had 1 loop(s) fused.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            " \n"
          ]
        }
      ]
    }
  ]
}